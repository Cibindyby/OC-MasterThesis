\chapter{Experimente und Evaluation}
\label{praktischer Teil}

\section{Aufbau der Experimente}
\label{sec:aufbauExperimente}

Für die Beantwortung der Forschungsfragen werden unterschiedliche Experimente ausgeführt, deren Ergebnisse in dieser Arbeit ausgewertet und interpretiert werden sollen.
Der Programmcode für die Experimente wurde in der Sprache Julia verfasst.
Dabei fand eine Orientierung an folgendem Code von Henning Cui statt: \cite{cuihen_cuihencgp_with_crossover_strategies_2024}\\
Um Ergebnisse von Ausgangsproblemen aus unterschiedlichen Domänen für eine umfangreichere Bewertung zur Verfügung zu stellen, werden mehrere Benchmark-Testszenarien überprüft.
Diese werden in den folgenden Abschnitten näher betrachtet.

\subsection{Testszenarien}
\label{subsec:testszenarien}

\subsubsection{Boolean Problems}
\label{subsubsec:booleanProblems}

Nach der Aussage von Kalkreuth et al. spielen Boolean Problems eine wichtige Rolle in der Forschung zu GP.
Grundsätzlich ist bei Boolean Problems das Ziel einen sinnvollen Zusammenhang zwischen Ein- und Ausgaben zu generieren, welcher von Boolean Funktionen bestimmt wird.
Diese können wiederum durch Boolean Ausdrücke mathematisch beschrieben werden.
Die verschiedenen Boolean Funktionen können durch Wahrheitstabellen dargestellt werden, in denen die jeweiligen Ein- und Ausgaben miteinander verknüpft werden. \cite{kalkreuth_towards_2023}
Das Ziel von CGP-Algorithmen ist es aus Eingängen die richtigen Ausgänge zu generieren, welche dem Mapping der Boolean Funktionen entsprechen.\\

Insgesamt werden in dieser Arbeit vier Boolean Benchmark Problems für die Evaluation der CGP Algorithmen betrachtet: 3-bit Parity, 16-4-bit Encode, 4-16-bit Decode und 3-bit Multiply (vereinfacht bezeichnet als Parity, Encode, Decode und Multiply).
Die Auswahl dieser beruht auf der Argumentationskette von Cui et al., die für sinnvoll befunden wird. \cite{cui_equidistant_2023}\\
Obwohl Parity als zu leichtes Ausgangsproblem für GP bezeichnet wird \cite{white_better_2013}, wird es häufig als Benchmarkproblem genutzt \cite{yu_neutrality_2001, kaufmann_kalkreuth_2017, kaufmann_kalkreuth_2020}.
Um Benchmarkprobleme mit unterschiedlichen Ein- und Ausgangsgrößen miteinzubeziehen, werden Encode und Decode verwendet.
Sinnvoll ist es ebenfalls Testprobleme verschiedener Schwierigkeitsstufen zu bewerten.
Multiply ist dabei ein vergleichsweise schwer zu lösendes Testproblem und wird deswegen herangezogen \cite{walker_2008}.\\

Das verwendete Standardfunktionsset aller vier Testszenarien beinhaltet die Boolean Rechenoperatoren AND, OR, NAND und NOR.
Außerdem wird die Standardfitnessfunktion für Boolean Benchmarkprobleme verwendet.
Diese wird definiert durch den Anteil an korrekt zugeordneten Bits. \cite{cui_equidistant_2023}
Das Stopp-Kriterium ist erfüllt, wenn die Fitness den Wert 0 erreicht.
Folgend werden die vier verwendeten Boolean Benchmark Problems näher erläutert:

\textbf{Parity:} N-bit Parity ist eine Mapping-Funktion, die angibt, ob die Summe der Komponenten eines Binär-Vektors gerade oder ungerade ist.
Bei 3-bit Parity handelt es sich dabei um Binär-Vektoren der Länge 3.
Das Evaluationsset besteht aus $2^N=2^3$ Testvektoren. \cite{hohil_1999}
Demnach gibt es für das CGP drei Eingaben (die Komponenten eines Binär-Vektors) und eine Ausgabe (Binärwert für \glqq gerade\grqq\space / \glqq ungerade\grqq).

\textbf{Encode:} Beim 16-4-bit Encoding wird aus einer 16-stelligen One-Hot-Kodierung ein 4-bit Integer erstellt.
Die One-Hot-Kodierung besteht dabei aus einem 16-stelligen Binär-Vektor, wobei nur eine Stelle mit einer 1 belegt ist, die restlichen Stellen sind 0.
Ziel ist es diejenige Stelle zu finden, die die 1 hält und diese als üblichen 4-bit Integer zu kodieren. \cite{cui_weighted_mutation, goldman_2015}
Daraus ergibt sich eine Eingabegröße von 16 und eine Ausgabegröße von vier.
Der Testdatensatz enthält 16 verschiedene One-Hot-Kodierungen, die umgewandelt werden sollen.

\textbf{Decode:} 4-16-bit Decode hat das genau umgekehrte Ziel als 16-4-bit Encode.
Es wird ein 4-bit Integer-Wert angegeben, der durch eine 16-bit One-Hot-Kodierung dargestellt werden soll. \cite{cui_weighted_mutation}
Demnach werden für 4-16-bit Decode vier Eingaben in 16 Ausgaben umgewandelt.
Der Testdatensatz besteht aus 16 verschiedenen 4-bit Integerwerten.

\textbf{Multiply:} Ziel von 3-bit Multiply ist die Multiplikation von zwei 3-bit Integer-Werten.
Das Ergebnis wird durch einen 6-bit Integer-Wert dargestellt. \cite{cui_weighted_mutation}
Folglich ist die Anzahl der CGP-Eingaben gleich 6, da beide 3-bit Faktoren als Eingang in das CGP-Modell einfließen müssen.
Für die Ausgabe werden ebenfalls 6 Binärausgaben benötigt.
Der Testdatensatz besteht aus $2^6=64$ verschiedenen Kombinationen der möglichen Binär-Faktoren.

\subsubsection{Symbolische Regression}
\label{subsubsec:symbolicRegression}

Symbolische Regression (SR) zählt seit Beginn von GP als Grundlage für methodologische Forschung und als primäres Anwendungsgebiet \cite{orzechowski}.
Das Ziel von SR ist das Erlernen einer Beziehung zwischen Ein- und Ausgängen nur aufgrund von gegebenen Daten.
Diese Beziehung beruht auf interpretierbaren mathematischen Ausdrücken.
Der Fehler von errechnetem und vorgegebenem Ausgang pro Eingang soll dabei minimiert werden. \cite{makke_interpretable_2024}

Die in dieser Arbeit verwendeten SR Probleme werden aus dem Paper von Cui et al. übernommen: Keijzer-6, Koza-3, Nguyen-7.
Im folgenden werden diese durch Keijzer, Koza und Nguyen abgekürzt.
Sie sind von der GP-Community empfohlen und wurden bereits in früheren Arbeiten verwendet
\cite{white_better_2013, kalkreuth_comprehensive_2020}. Die Pagie-1 Funktion wurde in dieser Arbeit aus Gründen des zeitlichen Rahmens nicht näher betrachtet. \\
Der verwendete Funktionssatz besteht aus den folgenden acht mathematischen Funktionen: Addition, Subtraktion, Multiplikation, Division, Sinus, Cosinus, natürlicher Logarithmus und Exponentialfunktion.
Bei der Division wird sichergestellt, dass eine Division durch null abgefangen wird. \cite{affenzeller_positional_2024}
Dabei wird der Wert 1,0 ausgegeben, statt eine Division auszuführen.
Zur Absicherung des natürlichen Logarithmus werden für alle Eingaben nur die absoluten Werte in die Berechnung einbezogen.
Für den Fall, dass die Eingabe gleich 0 ist, wird vergleichbar zur Division der Wert 1,0 zurückgegeben.
Da es bei der Programmierung mit Julia zu Fehlern kommen kann, wenn die Eingaben von Sinus oder Cosinus zu groß sind, werden diese Fälle ebenfalls abgefangen.
Dabei werden die Eingaben nicht weiter verrechnet sondern durchgereicht.\\
Für die Berechnung der Fitness wird der mittlere absolute Fehler zwischen vorhergesagter und tatsächlicher Ausgabe pro Eingabe berechnet.
Das Stopp-Kriterium ist erfüllt, sobald die Fitness den Wert 0,01 unterschreitet. \cite{affenzeller_positional_2024}\\
Die folgende Tabelle beschreibt die verwendeten SR Probleme näher.

\begin{table}[h]
	\centering
	\begin{tabular}{c | c | c | c | c}
		\textbf{Name} & \textbf{Variablen} & \textbf{Gleichung} & \textbf{Trainingsdaten} & \textbf{Testdaten}\\
		\hline
		Keijzer & 1 & $\sum\limits_{i}^{x}\frac{1}{i}$ & E[1, 50, 1] & E[1, 120, 1]\\
		\hline
		Koza & 1 & $x^6−2\cdot x^4+x^2$ & U[−1, 1, 20] & -\\
		\hline
		Nguyen & 1 & $ln(x + 1) + ln(x^2 + 1)$ & U[0, 2, 20]  & -\\
	\end{tabular}
	\caption{Beschreibung SR Benchmark Problems nach \cite{affenzeller_positional_2024}}
	\label{table:SRProblems}
\end{table}

Zu beobachten ist, dass in unterschiedlichen Papern verschiedene Keijzer-6 Funktionen beschrieben werden \cite{oliveira_analysing_2018, li_generative_2024, kommenda_local_2018}. 
In dieser Arbeit wurden alle SR Benchmark Probleme auf das Paper von Cui et al. bezogen \cite{affenzeller_positional_2024}.

\subsection{CGP-Konfigurationen}
\label{subsec:CGPkonfigurationen}

In dieser Arbeit werden unterschiedliche CGP-Konfigurationen miteinander verglichen und evaluiert. Diese werden in diesem Abschnitt näher beschrieben.\\
Ein Ziel der Arbeit ist es die Effizienz von Rekombination in CGP zu bewerten.
Ebenfalls sollen unterschiedliche Rekombinationsalgorithmen und -konfigurationen miteinander verglichen werden, um eine Aussage über deren Effektivität zu treffen.
Aus diesem Grund müssen für die unterschiedlichen Testszenarien mehrere Rekombinationskonfigurationen getestet werden.
Um eine Vergleichbarkeit der Ergebnisse zu gewährleisten müssen Selektion und Mutation in allen Experimenten gleichen Algorithmen entsprechen.
Diese werden im Folgenden beschrieben.\newline
\textbf{Selektion:} Für die Selektion wird in allen Experimenten das ($\mu$+$\lambda$)-Selektionsverfahren verwendet.
Dabei wurde für die CGP-Konfiguration ohne Rekombinationsschritt nicht $\mu = 1$ festgelegt, obwohl dies den Standard-Einstellungen eines CGP ohne Rekombination entspricht.
Dieser zusätzliche Freiheitsgrad soll einen ausgewogeneren Vergleich zwischen den CGP-Konfigurationen mit und ohne Rekombinationsschritt ermöglichen.
Für die Auswahl der Elitisten wird das neutral search Verfahren herangezogen.\\
\textbf{Mutation:} In allen Experimenten dieser Arbeit wird die Single Active Mutation angewendet.\\

Die nachfolgende Tabelle gibt alle Konfigurationen für die \textbf{Rekombination} an, die für jedes Testszenario aus Abschnitt \ref{subsec:testszenarien} getestet werden.

\begin{table}[h]
	\centering
	\begin{tabular}{c | c | c}
		\textbf{Rekombinationsverfahren} & \textbf{Art der Rekombinationsrate} & \textbf{Offset}\\
		\hline
		One-Point Rekombination & konstante Rekombinationsrate  & aktiv \\
		\hline
		Two-Point Rekombination & linear fallende Rekombinationsrate & inaktiv \\
		\hline
		Uniform Rekombination & Rekombinationsrate mit One-Fifth Regel & - \\
		\hline
		keine Rekombination &  - &  - \\
	\end{tabular}
	\caption{Konfigurationen Rekombination}
	\label{table:Rekombinationskonfigurationen}
\end{table}

Zu beachten ist, dass diese einzelnen Einstellungen miteinander kombiniert werden, solange es die Verfahren zulassen.
Falls keine Rekombination ausgeführt wird, wird selbstverständlich auch die Rekombinationsrate nicht angepasst und es kann kein Offset eingeführt werden.
Grundsätzlich werden die Konfigurationskombinationen nach folgendem Muster erstellt:
\begin{itemize}
	\item Auswahl Rekombinationsverfahren
	\item Auswahl Art der Rekombinationsrate
	\item Auswahl Offset aktiv / inaktiv
\end{itemize}

Dementsprechend ergeben sich 19 verschiedene Konfigurationen für den Rekombinationsschritt, die miteinander verglichen werden sollen. 


\subsection{Hyperparameteroptimierung}
\label{subsec:hpo}

Da CGP mehrere Hyperparameter ausweist, die die Effektivität eines CGP-Modells beeinflussen, muss eine Hyperparameteroptimierung ausgeführt werden, die einen optimierten Parametersatz ausgibt.
Für jede in Abschnitt \ref{subsec:CGPkonfigurationen} eingeführte CGP-Konfiguration wird eine eigene Hyperparameteroptimierung ausgeführt, da nicht von einem optimierten Datensatz auf den nächsten geschlussfolgert werden kann.
Außerdem müssen die Hyperparameter auf das jeweilige Testszenario angepasst werden.\\
Für die Hyperparameteroptimierungen in dieser Arbeit wird das Julia-Paket HyperOpt.jl verwendet \cite{carlson_baggepinnenhyperoptjl_2025}.
Mit Hilfe des Pakets können die Hyperparameter, sowie deren Wertebereiche angegeben werden, sodass eine automatisierte Optimierung stattfinden kann.
Eben diese werden in folgender Tabelle aufgelistet.

\begin{table}[h]
	\centering
	\begin{tabular}{c | c | c | c}
		\textbf{Parameter} & \textbf{min} & \textbf{max} & \textbf{Schrittweite}\\
		\hline
		Anzahl Rechenknoten & 50 & 2000 & 50 \\
		\hline
		$\mu$ (Anzahl Elitisten) & 2 & 20 & 2\\
		\hline
		$\lambda$ (Anzahl Nachkommen) & 10 & 60 & 2 \\
		\hline
		Offset Rekombination (in Iterationen)& 0 & 500 & 50\\
		\hline
		Konstante Rekombinationsrate & 0,1 & 1,0 & 0,1\\
		\hline
		Fallende Rekombinationsrate (Abzug) & 0,005 & 0,05 & 0,005\\
		\hline
		One-Fifth Regel Rekombinationsrate (Startwert Rate) & 0,3 & 0,05 & 0,75\\
	\end{tabular}
	\caption{Optimierte Hyperparameter und deren Wertebereiche}
	\label{table:hyperopt}
\end{table}

Zu beachten ist, dass $\mu <= \lambda$ gilt.
Außerdem werden die Einträge der Tabelle je nach CGP-Konfiguration verwendet.
Zum Beispiel wird der Wert \glqq Offset Rekombination\grqq\space nur verwendet, wenn der Rekombinationsoffset aktiv ist. 
Dieser Wert wird in Iterationen angegeben, in denen die Rekombination ausgesetzt wird.
Die obere Grenze des Offsets wurde abgeschätzt, indem die Iterationen derjenigen Tests betrachtet wurde, in denen der Offset inaktiv war.
Die drei letzten Zeilen der Tabelle geben die verschiedenen Arten an Rekombinationsraten an, die in dieser Arbeit verglichen werden.
Für jede dieser Ratenarten wird gezielt nur ein Hyperparameter verwendet, um die Rechenzeit der Hyperparameteroptimierung zu reduzieren.
Für die linear fallende Rekombinationsrate gibt dieser Parameter an, mit welcher Schrittweite die Rekombinationsrate pro Iteration sinkt.
In der One-Fifth Regel wird der Startwert der Rekombinationsrate angegeben, also diejenige Rekombinationsrate, mit der das CGP-Modell initialisiert wird.\\

In einer Optimierungsschleife werden pro Parametersatz 10 Testdurchläufe durchgeführt, in denen das CGP trainiert wird.
Für Boolean Problems wird die Effizienz die Parametersätze anhand der Iterationen gemessen, die der CGP-Algorithmus braucht, bis er konvergiert.
Bei symbolischer Regression bezieht sich der Vergleich auf die berechnete Fitness.
Es wurde eine Iterationsgrenze eingeführt, ab der der CGP-Algorithmus in der Hyperparameteroptimierung abbricht, um Rechenzeit zu sparen.
Diese Grenze wurde durch vorhergehende Tests so gesetzt, dass nur wenige Ausreißer diese überschreiten.
Trifft dies zu wird bei Boolean Problems die Anzahl an benötigten Iterationen verdoppelt, um so das gescheiterte Training härter zu bestrafen.\\
Nach 150 getesteten Parametersätzen bricht die Hyperparameteroptimierung ab und gibt den besten Parametersatz aus.\\

Das verwendete Julia-Paket bietet verschiedene Sampler an.
Der als Standardeinstellung zur Verfügung gestellte Sampler ist ein Random-Sampler.
Da der verwendete BHOB Sampler mit und ohne Hyperband keine Einsparungen in der Rechenzeit ergeben haben, wurde weiterhin der einfach zu konfigurierende Random-Sampler verwendet. 

TODO: in main Branch schauen, ob Hyperparameter Ranges so passen

\subsection{Teststruktur}
\label{subsec:struktur}

TODO: zwei Tests; einmal mit HPO für Endergebnisse und einmal ohne HPO für Veränderungen bei Änderung der Raten
angeben, wieso diese Tests gespalten werden => Rechenzeit HPO


\section{Evaluation}
\label{sec:Evaluation}

\begin{itemize}
    \item Versuchsaufbau und Durchführung
    \begin{itemize}
        \item an Hennings Code orientiert
        \item Testszenarien -> welche Testdaten und Berechnung fitness
        \begin{itemize}
            \item boolean Problems
            \item symbolic regression
            \item ggf. Ameisenoptimierungsproblem
        \end{itemize}
        \item weitere Einstellungen (Welche Selektionsverfahren, Mutationsverfahren, Rekomb...)
        \item Hyperparameteroptimierung
        \begin{itemize}
        	\item HPO wird in Grundlagen nicht erklärt also hier kurz erwähnen, dass die besten Parameter gesucht werden also eine HPO ausgeführt wird
            \item Welche Bib benutzt
            \item Welche Parameter optimiert; mit welchen Ranges
            \item 10 Ausführungen pro Optimierungsschritt
            \item Probleme Rechenzeit HPO
            \item verschiedene Sampler keinen Mehrwert
        \end{itemize}
        \item Ausführen mehrerer Durchläufe, um statistische Auswertung vorzunehmen
    \end{itemize}
    \item Ergebnisse und Evaluation
    \begin{itemize}
        \item Metriken zur Auswertung
        \item händische Auswertung des zeitlichen Verlaufs der Metriken (Mittelwert und Standardabweichung)
        \item bayesian Auswertung der Endergebnisse -> wie viele Iterationen (erklären wieso Bayes verwendet wird: Henning sagt in Paper, dass andere Verteilungen das Modell nicht gut beschreiben; siehe negative Werte für Iterationen)
        \item Plankett-Luce-Modell gibt Wahrscheinlichkeit bestes Ergebnis zu sein -> wie in Hennings Paper
        \item cmpbayes verwendet Markov Chain Monte-Carlo Sampling -> also auch verwenden
        \item HPDI für Bewertung der Endergebnisse (Iterationen bis konvergent)
        \item prior sensitivity analysis nicht machen (to ensure robustness of all models)
        \item ggf Bewertung der statistischen Aussagekraft mit ANOVA
    \end{itemize}
\end{itemize}

