\chapter{Experimente und Evaluation}
\label{praktischer Teil}

\section{Aufbau der Experimente}
\label{sec:aufbauExperimente}

Für die Beantwortung der Forschungsfragen werden unterschiedliche Experimente ausgeführt, deren Ergebnisse in dieser Arbeit ausgewertet und interpretiert werden sollen.
Der Programmcode für die Experimente wurde in der Sprache Julia verfasst.
Dabei fand eine Orientierung an folgendem Code von Henning Cui statt: \cite{cuihen_cuihencgp_with_crossover_strategies_2024}\\
Um Ergebnisse von Ausgangsproblemen aus unterschiedlichen Domänen für eine umfangreichere Bewertung zur Verfügung zu stellen, werden mehrere Benchmark-Testszenarien überprüft.
Diese werden in den folgenden Abschnitten näher betrachtet.

\subsection{Testszenarien}
\label{subsec:testszenarien}

\subsubsection{Boolean Problems}
\label{subsubsec:booleanProblems}

Nach der Aussage von Kalkreuth et al. spielen Boolean Problems eine wichtige Rolle in der Forschung zu GP.
Grundsätzlich ist bei Boolean Problems das Ziel einen sinnvollen Zusammenhang zwischen Ein- und Ausgaben zu generieren, welcher von Boolean Funktionen bestimmt wird.
Diese können wiederum durch Boolean Ausdrücke mathematisch beschrieben werden.
Die verschiedenen Boolean Funktionen können durch Wahrheitstabellen dargestellt werden, in denen die jeweiligen Ein- und Ausgaben miteinander verknüpft werden. \cite{kalkreuth_towards_2023}
Das Ziel von CGP-Algorithmen ist es aus Eingängen die richtigen Ausgänge zu generieren, welche dem Mapping der Boolean Funktionen entsprechen.\\

Insgesamt werden in dieser Arbeit vier Boolean Benchmark Problems für die Evaluation der CGP Algorithmen betrachtet: 3-bit Parity, 16-4-bit Encode, 4-16-bit Decode und 3-bit Multiply (vereinfacht bezeichnet als Parity, Encode, Decode und Multiply).
Die Auswahl dieser beruht auf der Argumentationskette von Cui et al., die für sinnvoll befunden wird. \cite{cui_equidistant_2023}\\
Obwohl Parity als zu leichtes Ausgangsproblem für GP bezeichnet wird \cite{white_better_2013}, wird es häufig als Benchmarkproblem genutzt \cite{yu_neutrality_2001, kaufmann_kalkreuth_2017, kaufmann_kalkreuth_2020}.
Um Benchmarkprobleme mit unterschiedlichen Ein- und Ausgangsgrößen miteinzubeziehen, werden Encode und Decode verwendet.
Sinnvoll ist es ebenfalls Testprobleme verschiedener Schwierigkeitsstufen zu bewerten.
Multiply ist dabei ein vergleichsweise schwer zu lösendes Testproblem und wird deswegen herangezogen \cite{walker_2008}.\\

Das verwendete Standardfunktionsset aller vier Testszenarien beinhaltet die Boolean Rechenoperatoren AND, OR, NAND und NOR.
Außerdem wird die Standardfitnessfunktion für Boolean Benchmarkprobleme verwendet.
Diese wird definiert durch den Anteil an korrekt zugeordneten Bits. \cite{cui_equidistant_2023}
Folgend werden die vier verwendeten Boolean Benchmark Problems näher erläutert:

\textbf{Parity:} N-bit Parity ist eine Mapping-Funktion, die angibt, ob die Summe der Komponenten eines Binär-Vektors gerade oder ungerade ist.
Bei 3-bit Parity handelt es sich dabei um Binär-Vektoren der Länge 3.
Das Evaluationsset besteht aus $2^N=2^3$ Testvektoren. \cite{hohil_1999}
Demnach gibt es für das CGP drei Eingaben (die Komponenten eines Binär-Vektors) und eine Ausgabe (Binärwert für \glqq gerade\grqq\space / \glqq ungerade\grqq).

\textbf{Encode:} Beim 16-4-bit Encoding wird aus einer 16-stelligen One-Hot-Kodierung ein 4-bit Integer erstellt.
Die One-Hot-Kodierung besteht dabei aus einem 16-stelligen Binär-Vektor, wobei nur eine Stelle mit einer 1 belegt ist, die restlichen Stellen sind 0.
Ziel ist es diejenige Stelle zu finden, die die 1 hält und diese als üblichen 4-bit Integer zu kodieren. \cite{cui_weighted_mutation, goldman_2015}
Daraus ergibt sich eine Eingabegröße von 16 und eine Ausgabegröße von vier.
Der Testdatensatz enthält 16 verschiedene One-Hot-Kodierungen, die umgewandelt werden sollen.

\textbf{Decode:} 4-16-bit Decode hat das genau umgekehrte Ziel als 16-4-bit Encode.
Es wird ein 4-bit Integer-Wert angegeben, der durch eine 16-bit One-Hot-Kodierung dargestellt werden soll. \cite{cui_weighted_mutation}
Demnach werden für 4-16-bit Decode vier Eingaben in 16 Ausgaben umgewandelt.
Der Testdatensatz besteht aus 16 verschiedenen 4-bit Integerwerten.

\textbf{Multiply:} Ziel von 3-bit Multiply ist die Multiplikation von zwei 3-bit Integer-Werten.
Das Ergebnis wird durch einen 6-bit Integer-Wert dargestellt. \cite{cui_weighted_mutation}
Folglich ist die Anzahl der CGP-Eingaben gleich 6, da beide 3-bit Faktoren als Eingang in das CGP-Modell einfließen müssen.
Für die Ausgabe werden ebenfalls 6 Binärausgaben benötigt.
Der Testdatensatz besteht aus $2^6=64$ verschiedenen Kombinationen der möglichen Binär-Faktoren.

\subsubsection{Symbolische Regression}
\label{subsubsec:symbolicRegression}

\section{Evaluation}
\label{sec:Evaluation}

\begin{itemize}
    \item Versuchsaufbau und Durchführung
    \begin{itemize}
        \item an Hennings Code orientiert
        \item Testszenarien -> welche Testdaten und Berechnung fitness
        \begin{itemize}
            \item boolean Problems
            \item symbolic regression
            \item ggf. Ameisenoptimierungsproblem
        \end{itemize}
        \item weitere Einstellungen (Welche Selektionsverfahren, Mutationsverfahren, Rekomb...)
        \item Hyperparameteroptimierung
        \begin{itemize}
        	\item HPO wird in Grundlagen nicht erklärt also hier kurz erwähnen, dass die besten Parameter gesucht werden also eine HPO ausgeführt wird
            \item Welche Bib benutzt
            \item Welche Parameter optimiert; mit welchen Ranges
            \item 10 Ausführungen pro Optimierungsschritt
            \item Probleme Rechenzeit HPO
            \item verschiedene Sampler keinen Mehrwert
        \end{itemize}
        \item Ausführen mehrerer Durchläufe, um statistische Auswertung vorzunehmen
    \end{itemize}
    \item Ergebnisse und Evaluation
    \begin{itemize}
        \item Metriken zur Auswertung
        \item händische Auswertung des zeitlichen Verlaufs der Metriken (Mittelwert und Standardabweichung)
        \item bayesian Auswertung der Endergebnisse -> wie viele Iterationen (erklären wieso Bayes verwendet wird: Henning sagt in Paper, dass andere Verteilungen das Modell nicht gut beschreiben; siehe negative Werte für Iterationen)
        \item Plankett-Luce-Modell gibt Wahrscheinlichkeit bestes Ergebnis zu sein -> wie in Hennings Paper
        \item cmpbayes verwendet Markov Chain Monte-Carlo Sampling -> also auch verwenden
        \item HPDI für Bewertung der Endergebnisse (Iterationen bis konvergent)
        \item prior sensitivity analysis nicht machen (to ensure robustness of all models)
        \item ggf Bewertung der statistischen Aussagekraft mit ANOVA
    \end{itemize}
\end{itemize}

