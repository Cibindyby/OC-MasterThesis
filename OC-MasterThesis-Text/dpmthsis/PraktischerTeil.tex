\chapter{Experimente und Evaluation}
\label{praktischer Teil}

\section{Aufbau der Experimente}
\label{sec:aufbauExperimente}

Für die Beantwortung der Forschungsfragen werden unterschiedliche Experimente ausgeführt, deren Ergebnisse in dieser Arbeit ausgewertet und interpretiert werden sollen.
Der Programmcode für die Experimente wurde in der Sprache Julia verfasst.
Dabei fand eine Orientierung an folgendem Code von Henning Cui statt: \cite{cuihen_cuihencgp_with_crossover_strategies_2024}\\
Um Ergebnisse von Ausgangsproblemen aus unterschiedlichen Domänen für eine umfangreichere Bewertung zur Verfügung zu stellen, werden mehrere Benchmark-Testszenarien überprüft.
Diese werden in den folgenden Abschnitten näher betrachtet.

\subsection{Testszenarien}
\label{subsec:testszenarien}

\subsubsection{Boolean Problems}
\label{subsubsec:booleanProblems}

Nach der Aussage von Kalkreuth et al. spielen Boolean Problems eine wichtige Rolle in der Forschung zu GP.
Grundsätzlich ist bei Boolean Problems das Ziel einen sinnvollen Zusammenhang zwischen Ein- und Ausgaben zu generieren, welcher von Boolean Funktionen bestimmt wird.
Diese können wiederum durch Boolean Ausdrücke mathematisch beschrieben werden.
Die verschiedenen Boolean Funktionen können durch Wahrheitstabellen dargestellt werden, in denen die jeweiligen Ein- und Ausgaben miteinander verknüpft werden. \cite{kalkreuth_towards_2023}
Das Ziel von CGP-Algorithmen ist es aus Eingängen die richtigen Ausgänge zu generieren, welche dem Mapping der Boolean Funktionen entsprechen.\\

Insgesamt werden in dieser Arbeit vier Boolean Benchmark Problems für die Evaluation der CGP Algorithmen betrachtet: 3-bit Parity, 16-4-bit Encode, 4-16-bit Decode und 3-bit Multiply (vereinfacht bezeichnet als Parity, Encode, Decode und Multiply).
Die Auswahl dieser beruht auf der Argumentationskette von Cui et al., die für sinnvoll befunden wird. \cite{cui_equidistant_2023}\\
Obwohl Parity als zu leichtes Ausgangsproblem für GP bezeichnet wird \cite{white_better_2013}, wird es häufig als Benchmarkproblem genutzt \cite{yu_neutrality_2001, kaufmann_kalkreuth_2017, kaufmann_kalkreuth_2020}.
Um Benchmarkprobleme mit unterschiedlichen Ein- und Ausgangsgrößen miteinzubeziehen, werden Encode und Decode verwendet.
Sinnvoll ist es ebenfalls Testprobleme verschiedener Schwierigkeitsstufen zu bewerten.
Multiply ist dabei ein vergleichsweise schwer zu lösendes Testproblem und wird deswegen herangezogen \cite{walker_2008}.\\

Das verwendete Standardfunktionsset aller vier Testszenarien beinhaltet die Boolean Rechenoperatoren AND, OR, NAND und NOR.
Außerdem wird die Standardfitnessfunktion für Boolean Benchmarkprobleme verwendet.
Diese wird definiert durch den Anteil an korrekt zugeordneten Bits. \cite{cui_equidistant_2023}
Das Stopp-Kriterium ist erfüllt, wenn die Fitness den Wert 0 erreicht.
Folgend werden die vier verwendeten Boolean Benchmark Problems näher erläutert:

\textbf{Parity:} N-bit Parity ist eine Mapping-Funktion, die angibt, ob die Summe der Komponenten eines Binär-Vektors gerade oder ungerade ist.
Bei 3-bit Parity handelt es sich dabei um Binär-Vektoren der Länge 3.
Das Evaluationsset besteht aus $2^N=2^3$ Testvektoren. \cite{hohil_1999}
Demnach gibt es für das CGP drei Eingaben (die Komponenten eines Binär-Vektors) und eine Ausgabe (Binärwert für \glqq gerade\grqq\space / \glqq ungerade\grqq).

\textbf{Encode:} Beim 16-4-bit Encoding wird aus einer 16-stelligen One-Hot-Kodierung ein 4-bit Integer erstellt.
Die One-Hot-Kodierung besteht dabei aus einem 16-stelligen Binär-Vektor, wobei nur eine Stelle mit einer 1 belegt ist, die restlichen Stellen sind 0.
Ziel ist es diejenige Stelle zu finden, die die 1 hält und diese als üblichen 4-bit Integer zu kodieren. \cite{cui_weighted_mutation, goldman_2015}
Daraus ergibt sich eine Eingabegröße von 16 und eine Ausgabegröße von vier.
Der Testdatensatz enthält 16 verschiedene One-Hot-Kodierungen, die umgewandelt werden sollen.

\textbf{Decode:} 4-16-bit Decode hat das genau umgekehrte Ziel als 16-4-bit Encode.
Es wird ein 4-bit Integer-Wert angegeben, der durch eine 16-bit One-Hot-Kodierung dargestellt werden soll. \cite{cui_weighted_mutation}
Demnach werden für 4-16-bit Decode vier Eingaben in 16 Ausgaben umgewandelt.
Der Testdatensatz besteht aus 16 verschiedenen 4-bit Integerwerten.

\textbf{Multiply:} Ziel von 3-bit Multiply ist die Multiplikation von zwei 3-bit Integer-Werten.
Das Ergebnis wird durch einen 6-bit Integer-Wert dargestellt. \cite{cui_weighted_mutation}
Folglich ist die Anzahl der CGP-Eingaben gleich 6, da beide 3-bit Faktoren als Eingang in das CGP-Modell einfließen müssen.
Für die Ausgabe werden ebenfalls 6 Binärausgaben benötigt.
Der Testdatensatz besteht aus $2^6=64$ verschiedenen Kombinationen der möglichen Binär-Faktoren.

\subsubsection{Symbolische Regression}
\label{subsubsec:symbolicRegression}

Symbolische Regression (SR) zählt seit Beginn von GP als Grundlage für methodologische Forschung und als primäres Anwendungsgebiet \cite{orzechowski}.
Das Ziel von SR ist das Erlernen einer Beziehung zwischen Ein- und Ausgängen nur aufgrund von gegebenen Daten.
Diese Beziehung beruht auf interpretierbaren mathematischen Ausdrücken.
Der Fehler von errechnetem und vorgegebenem Ausgang pro Eingang soll dabei minimiert werden. \cite{makke_interpretable_2024}

Die in dieser Arbeit verwendeten SR Probleme werden aus dem Paper von Cui et al. übernommen: Keijzer-6, Koza-3, Nguyen-7.
Im folgenden werden diese durch Keijzer, Koza und Nguyen abgekürzt.
Sie sind von der GP-Community empfohlen und wurden bereits in früheren Arbeiten verwendet
\cite{white_better_2013, kalkreuth_comprehensive_2020}. Die Pagie-1 Funktion wurde in dieser Arbeit aus Gründen des zeitlichen Rahmens nicht näher betrachtet. \\
Der verwendete Funktionssatz besteht aus den folgenden acht mathematischen Funktionen: Addition, Subtraktion, Multiplikation, Division, Sinus, Cosinus, natürlicher Logarithmus und Exponentialfunktion.
Bei der Division wird sichergestellt, dass eine Division durch null abgefangen wird. \cite{affenzeller_positional_2024}
Dabei wird der Wert 1,0 ausgegeben, statt eine Division auszuführen.
Zur Absicherung des natürlichen Logarithmus werden für alle Eingaben nur die absoluten Werte in die Berechnung einbezogen.
Für den Fall, dass die Eingabe gleich 0 ist, wird vergleichbar zur Division der Wert 1,0 zurückgegeben.
Da es bei der Programmierung mit Julia zu Fehlern kommen kann, wenn die Eingaben von Sinus oder Cosinus zu groß sind, werden diese Fälle ebenfalls abgefangen.
Dabei werden die Eingaben nicht weiter verrechnet sondern durchgereicht.\\
Für die Berechnung der Fitness wird der mittlere absolute Fehler zwischen vorhergesagter und tatsächlicher Ausgabe pro Eingabe berechnet.
Das Stopp-Kriterium ist erfüllt, sobald die Fitness den Wert 0,01 unterschreitet. \cite{affenzeller_positional_2024}\\
Die folgende Tabelle beschreibt die verwendeten SR Probleme näher.

\begin{table}[h]
	\centering
	\begin{tabular}{l | c | c | c | c}
		Name & Variablen & Gleichung & Trainingsdatensatz & Testdatensatz\\
		\hline
		Keijzer & 1 & $\sum\limits_{i}^{x}\frac{1}{i}$ & E[1, 50, 1] & E[1, 120, 1]\\
		\hline
		Koza & 1 & $x^6−2\cdot x^4+x^2$ & U[−1, 1, 20] & -\\
		\hline
		Nguyen & 1 & $ln(x + 1) + ln(x^2 + 1)$ & U[0, 2, 20]  & -\\
	\end{tabular}
	\caption{Beschreibung SR Benchmark Problems nach \cite{affenzeller_positional_2024}}
	\label{table:SRProblems}
\end{table}

Zu beobachten ist, dass in unterschiedlichen Papern verschiedene Keijzer-6 Funktionen beschrieben werden \cite{oliveira_analysing_2018, li_generative_2024, kommenda_local_2018}. 
In dieser Arbeit wurden alle SR Benchmark Probleme auf das Paper von Cui et al. bezogen \cite{affenzeller_positional_2024}.

\subsection{CGP-Konfigurationen}
\label{subsec:CGPkonfigurationen}

In dieser Arbeit werden unterschiedliche CGP-Konfigurationen evaluiert. Diese werden in diesem Abschnitt näher beschrieben.\\
TODO: Konfigurationen beschreiben -> Selektion, Mutation, Rekombination, Raten; dann Tabelle die alle Kombinationen listet

\section{Evaluation}
\label{sec:Evaluation}

\begin{itemize}
    \item Versuchsaufbau und Durchführung
    \begin{itemize}
        \item an Hennings Code orientiert
        \item Testszenarien -> welche Testdaten und Berechnung fitness
        \begin{itemize}
            \item boolean Problems
            \item symbolic regression
            \item ggf. Ameisenoptimierungsproblem
        \end{itemize}
        \item weitere Einstellungen (Welche Selektionsverfahren, Mutationsverfahren, Rekomb...)
        \item Hyperparameteroptimierung
        \begin{itemize}
        	\item HPO wird in Grundlagen nicht erklärt also hier kurz erwähnen, dass die besten Parameter gesucht werden also eine HPO ausgeführt wird
            \item Welche Bib benutzt
            \item Welche Parameter optimiert; mit welchen Ranges
            \item 10 Ausführungen pro Optimierungsschritt
            \item Probleme Rechenzeit HPO
            \item verschiedene Sampler keinen Mehrwert
        \end{itemize}
        \item Ausführen mehrerer Durchläufe, um statistische Auswertung vorzunehmen
    \end{itemize}
    \item Ergebnisse und Evaluation
    \begin{itemize}
        \item Metriken zur Auswertung
        \item händische Auswertung des zeitlichen Verlaufs der Metriken (Mittelwert und Standardabweichung)
        \item bayesian Auswertung der Endergebnisse -> wie viele Iterationen (erklären wieso Bayes verwendet wird: Henning sagt in Paper, dass andere Verteilungen das Modell nicht gut beschreiben; siehe negative Werte für Iterationen)
        \item Plankett-Luce-Modell gibt Wahrscheinlichkeit bestes Ergebnis zu sein -> wie in Hennings Paper
        \item cmpbayes verwendet Markov Chain Monte-Carlo Sampling -> also auch verwenden
        \item HPDI für Bewertung der Endergebnisse (Iterationen bis konvergent)
        \item prior sensitivity analysis nicht machen (to ensure robustness of all models)
        \item ggf Bewertung der statistischen Aussagekraft mit ANOVA
    \end{itemize}
\end{itemize}

