\chapter{Praktischer Teil}
\label{praktischer Teil}

\section{Aufbau der Experimente}
\label{sec:aufbauExperimente}

Für die Beantwortung der Forschungsfragen werden unterschiedliche Experimente ausgeführt, deren Ergebnisse in dieser Arbeit ausgewertet und interpretiert werden sollen.
Der Programmcode für die Experimente wurde in der Sprache Julia verfasst.
Dabei fand eine Orientierung an folgendem Code von Henning Cui statt: \cite{cuihen_cuihencgp_with_crossover_strategies_2024}\\
Um Ergebnisse von Ausgangsproblemen aus unterschiedlichen Domänen für eine umfangreichere Bewertung zur Verfügung zu stellen, werden mehrere Benchmark-Testszenarien überprüft.
Diese werden in den folgenden Abschnitten näher betrachtet.

\subsection{Testszenarien}
\label{subsec:testszenarien}

\subsubsection{Boolean Problems}
\label{subsubsec:booleanProblems}

Nach der Aussage von Kalkreuth et al. spielen Boolean Problems eine wichtige Rolle in der Forschung zu GP.
Grundsätzlich ist bei Boolean Problems das Ziel einen sinnvollen Zusammenhang zwischen Ein- und Ausgaben zu generieren, welcher von Boolean Funktionen bestimmt wird.
Diese können wiederum durch Boolean Ausdrücke mathematisch beschrieben werden.
Die verschiedenen Boolean Funktionen können durch Wahrheitstabellen dargestellt werden, in denen die jeweiligen Ein- und Ausgaben miteinander verknüpft werden. \cite{kalkreuth_towards_2023}
Das Ziel von CGP-Algorithmen ist es aus Eingängen die richtigen Ausgänge zu generieren, welche dem Mapping der Boolean Funktionen entsprechen.\\

Insgesamt werden in dieser Arbeit vier Boolean Benchmark Problems für die Evaluation der CGP Algorithmen betrachtet: 3-bit Parity, 16-4-bit Encode, 4-16-bit Decode und 3-bit Multiply (vereinfacht bezeichnet als Parity, Encode, Decode und Multiply).
Die Auswahl dieser beruht auf der Argumentationskette von Cui et al., die für sinnvoll befunden wird. \cite{cui_equidistant_2023}\\
Obwohl Parity als zu leichtes Ausgangsproblem für GP bezeichnet wird \cite{white_better_2013}, wird es häufig als Benchmarkproblem genutzt \cite{yu_neutrality_2001, kaufmann_kalkreuth_2017, kaufmann_kalkreuth_2020}.
Um Benchmarkprobleme mit unterschiedlichen Ein- und Ausgangsgrößen miteinzubeziehen, werden Encode und Decode verwendet.
Sinnvoll ist es ebenfalls Testprobleme verschiedener Schwierigkeitsstufen zu bewerten.
Multiply ist dabei ein vergleichsweise schwer zu lösendes Testproblem und wird deswegen herangezogen \cite{walker_2008}.\\

Das verwendete Standardfunktionsset aller vier Testszenarien beinhaltet die Boolean Rechenoperatoren AND, OR, NAND und NOR.
Außerdem wird die Standardfitnessfunktion für Boolean Benchmarkprobleme verwendet.
Diese wird definiert durch den Anteil an korrekt zugeordneten Bits. \cite{cui_equidistant_2023}\\

Folgend werden die vier verwendeten Boolean Benchmark Problems näher erläutert:\\
\textbf{Parity:} \cite{hohil_1999}TODO: Anzahl In/Outputs, Berechnung\\
\textbf{Encode:} TODO: Anzahl In/Outputs, Berechnung\\
\textbf{Decode:} TODO: Anzahl In/Outputs, Berechnung\\
\textbf{Multiply:} TODO: Anzahl In/Outputs, Berechnung\\

\subsubsection{Symbolische Regression}
\label{subsubsec:symbolicRegression}

\section{Ergebnisse}
\label{Ergebnisse}

\begin{itemize}
    \item Versuchsaufbau und Durchführung
    \begin{itemize}
        \item an Hennings Code orientiert
        \item Testszenarien -> welche Testdaten und Berechnung fitness
        \begin{itemize}
            \item boolean Problems
            \item symbolic regression
            \item ggf. Ameisenoptimierungsproblem
        \end{itemize}
        \item weitere Einstellungen (Welche Selektionsverfahren, Mutationsverfahren, Rekomb...)
        \item Hyperparameteroptimierung
        \begin{itemize}
        	\item HPO wird in Grundlagen nicht erklärt also hier kurz erwähnen, dass die besten Parameter gesucht werden also eine HPO ausgeführt wird
            \item Welche Bib benutzt
            \item Welche Parameter optimiert; mit welchen Ranges
            \item 10 Ausführungen pro Optimierungsschritt
            \item Probleme Rechenzeit HPO
            \item verschiedene Sampler keinen Mehrwert
        \end{itemize}
        \item Ausführen mehrerer Durchläufe, um statistische Auswertung vorzunehmen
    \end{itemize}
    \item Ergebnisse und Evaluation
    \begin{itemize}
        \item Metriken zur Auswertung
        \item händische Auswertung des zeitlichen Verlaufs der Metriken (Mittelwert und Standardabweichung)
        \item bayesian Auswertung der Endergebnisse -> wie viele Iterationen (erklären wieso Bayes verwendet wird: Henning sagt in Paper, dass andere Verteilungen das Modell nicht gut beschreiben; siehe negative Werte für Iterationen)
        \item Plankett-Luce-Modell gibt Wahrscheinlichkeit bestes Ergebnis zu sein -> wie in Hennings Paper
        \item cmpbayes verwendet Markov Chain Monte-Carlo Sampling -> also auch verwenden
        \item HPDI für Bewertung der Endergebnisse (Iterationen bis konvergent)
        \item prior sensitivity analysis nicht machen (to ensure robustness of all models)
        \item ggf Bewertung der statistischen Aussagekraft mit ANOVA
    \end{itemize}
\end{itemize}

