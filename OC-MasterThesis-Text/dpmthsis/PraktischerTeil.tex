\chapter{Experimente und Evaluation}
\label{praktischer Teil}

\section{Aufbau der Experimente}
\label{sec:aufbauExperimente}

Für die Beantwortung der Forschungsfragen werden unterschiedliche Experimente ausgeführt, deren Ergebnisse in dieser Arbeit ausgewertet und interpretiert werden sollen.
Der Programmcode für die Experimente wurde in der Sprache Julia verfasst.
Dabei fand eine Orientierung an folgendem Code von Henning Cui statt: \cite{cuihen_cuihencgp_with_crossover_strategies_2024}\\
Um Ergebnisse von Ausgangsproblemen aus unterschiedlichen Domänen für eine umfangreichere Bewertung zur Verfügung zu stellen, werden mehrere Benchmark-Testszenarien überprüft.
Diese werden in den folgenden Abschnitten näher betrachtet.

\subsection{Testszenarien}
\label{subsec:testszenarien}

\subsubsection{Boolesche Probleme}
\label{subsubsec:booleanProblems}

Nach der Aussage von Kalkreuth et al. spielen \emph{Boolesche Probleme} eine wichtige Rolle in der Forschung zu GP.
Grundsätzlich ist bei Booleschen Problemen das Ziel einen sinnvollen Zusammenhang zwischen Ein- und Ausgaben zu generieren, welcher von Booleschen Funktionen bestimmt wird.
Diese können wiederum durch Boolesche Ausdrücke mathematisch beschrieben werden.
Die verschiedenen Booleschen Funktionen können durch Wahrheitstabellen dargestellt werden, in denen die jeweiligen Ein- und Ausgaben miteinander verknüpft werden. \cite{kalkreuth_towards_2023}
Das Ziel von CGP-Algorithmen ist es aus Eingängen die richtigen Ausgänge zu generieren, welche dem Mapping der Boolean Funktionen entsprechen.\\

Insgesamt werden in dieser Arbeit vier Boolesche Benchmarkprobleme für die Evaluation der CGP-Algorithmen betrachtet: 3-bit Parity, 16-4-bit Encode, 4-16-bit Decode und 3-bit Multiply (vereinfacht bezeichnet als Parity, Encode, Decode und Multiply).\\
Obwohl Parity als zu leichtes Ausgangsproblem für GP bezeichnet wird \cite{white_better_2013}, wird es häufig als Benchmarkproblem genutzt \cite{yu_neutrality_2001, kaufmann_kalkreuth_2017, kaufmann_kalkreuth_2020}.
Um Benchmarkprobleme mit unterschiedlichen Ein- und Ausgangsgrößen miteinzubeziehen, werden Encode und Decode verwendet.
Sinnvoll ist es ebenfalls Testprobleme verschiedener Schwierigkeitsstufen zu bewerten.
Multiply ist dabei ein vergleichsweise schwer zu lösendes Testproblem und wird deswegen herangezogen \cite{walker_2008}.\\

Das verwendete Standardfunktionsset aller vier Testszenarien beinhaltet die Boolesche Rechenoperatoren AND, OR, NAND und NOR.
Außerdem wird die Standardfitnessfunktion für Boolesche Benchmarkprobleme verwendet.
Diese wird definiert durch den Anteil an korrekt zugeordneten Bits. \cite{cui_equidistant_2023}
Das Stopp-Kriterium ist erfüllt, wenn die Fitness den Wert 0 erreicht.
Folgend werden die vier verwendeten Boolesche Benchmarkprobleme näher erläutert:

\textbf{Parity:} N-bit Parity ist eine Mapping-Funktion, die angibt, ob die Summe der Komponenten eines Binär-Vektors gerade oder ungerade ist.
Bei 3-bit Parity handelt es sich dabei um Binär-Vektoren der Länge 3.
Das Evaluationsset besteht aus $2^N=2^3$ Testvektoren. \cite{hohil_1999}
Demnach gibt es für das CGP drei Eingaben (die Komponenten eines Binär-Vektors) und eine Ausgabe (Binärwert für \glqq gerade\grqq\space / \glqq ungerade\grqq).

\textbf{Encode:} Beim 16-4-bit Encoding wird aus einer 16-stelligen One-Hot-Kodierung ein 4-bit Integer erstellt.
Die One-Hot-Kodierung besteht dabei aus einem 16-stelligen Binär-Vektor, wobei nur eine Stelle mit einer 1 belegt ist, die restlichen Stellen sind 0.
Ziel ist es diejenige Stelle zu finden, die die 1 hält und diese als üblichen 4-bit Integer zu kodieren. \cite{cui_weighted_mutation, goldman_2015}
Daraus ergibt sich eine Eingabegröße von 16 und eine Ausgabegröße von vier.
Der Testdatensatz enthält 16 verschiedene One-Hot-Kodierungen, die umgewandelt werden sollen.

\textbf{Decode:} 4-16-bit Decode hat das genau umgekehrte Ziel als 16-4-bit Encode.
Es wird ein 4-bit Integer-Wert angegeben, der durch eine 16-bit One-Hot-Kodierung dargestellt werden soll. \cite{cui_weighted_mutation}
Demnach werden für 4-16-bit Decode vier Eingaben in 16 Ausgaben umgewandelt.
Der Testdatensatz besteht aus 16 verschiedenen 4-bit Integerwerten.

\textbf{Multiply:} Ziel von 3-bit Multiply ist die Multiplikation von zwei 3-bit Integer-Werten.
Das Ergebnis wird durch einen 6-bit Integer-Wert dargestellt. \cite{cui_weighted_mutation}
Folglich ist die Anzahl der CGP-Eingaben gleich 6, da beide 3-bit Faktoren als Eingang in das CGP-Modell einfließen müssen.
Für die Ausgabe werden ebenfalls 6 Binärausgaben benötigt.
Der Testdatensatz besteht aus $2^6=64$ verschiedenen Kombinationen der möglichen Binär-Faktoren.

\subsubsection{Symbolische Regression}
\label{subsubsec:symbolicRegression}

\emph{Symbolische Regression} (SR) zählt seit Beginn von GP als Grundlage für methodologische Forschung und als primäres Anwendungsgebiet \cite{orzechowski}.
Das Ziel von SR ist das Erlernen einer Beziehung zwischen Ein- und Ausgängen nur aufgrund von gegebenen Daten.
Diese Beziehung beruht auf interpretierbaren mathematischen Ausdrücken.
Der Fehler von errechnetem und vorgegebenem Ausgang pro Eingang soll dabei minimiert werden. \cite{makke_interpretable_2024}

Die in dieser Arbeit verwendeten SR Probleme werden aus dem Paper von Cui et al. übernommen: Keijzer-6, Koza-3, Nguyen-7.
Im folgenden werden diese durch Keijzer, Koza und Nguyen abgekürzt.
Sie sind von der GP-Community empfohlen und wurden bereits in früheren Arbeiten verwendet
\cite{white_better_2013, kalkreuth_comprehensive_2020}.\\
Der verwendete Funktionssatz besteht aus den folgenden acht mathematischen Funktionen: Addition, Subtraktion, Multiplikation, Division, Sinus, Cosinus, natürlicher Logarithmus und Exponentialfunktion.
Bei der Division wird sichergestellt, dass eine Division durch null abgefangen wird. \cite{affenzeller_positional_2024}
Dabei wird der Wert 1,0 ausgegeben, statt eine Division durch null auszuführen.
Zur Absicherung des natürlichen Logarithmus werden für alle Eingaben nur die absoluten Werte in die Berechnung einbezogen.
Für den Fall, dass die Eingabe gleich 0 ist, wird vergleichbar zur Division der Wert 1,0 zurückgegeben.
Da es bei der Programmierung mit Julia zu Fehlern kommen kann, wenn die Eingaben von Sinus oder Cosinus zu groß sind, werden diese Fälle ebenfalls abgefangen.
Dabei werden die Eingaben nicht weiter verrechnet sondern durchgereicht.\\
Für die Berechnung der Fitness wird der mittlere absolute Fehler zwischen vorhergesagter und tatsächlicher Ausgabe pro Eingabe berechnet.
Das Stopp-Kriterium ist erfüllt, sobald die Fitness den Wert 0,01 unterschreitet. \cite{affenzeller_positional_2024}\\
Die folgende Tabelle \ref{table:SRProblems} beschreibt die verwendeten SR Probleme näher.

\begin{table}[H]
	\centering
	\begin{tabular}{c | c | c | c | c}
		\textbf{Name} & \textbf{Variablen} & \textbf{Gleichung} & \textbf{Trainingsdaten} & \textbf{Testdaten}\\
		\hline
		Keijzer & 1 & $\sum\limits_{i}^{x}\frac{1}{i}$ & E[1, 50, 1] & E[1, 120, 1]\\
		\hline
		Koza & 1 & $x^6−2\cdot x^4+x^2$ & U[−1, 1, 20] & -\\
		\hline
		Nguyen & 1 & $ln(x + 1) + ln(x^2 + 1)$ & U[0, 2, 20]  & -\\
	\end{tabular}
	\caption{Beschreibung SR Benchmarkprobleme nach \cite{affenzeller_positional_2024}}
	\label{table:SRProblems}
\end{table}

Zu beobachten ist, dass in unterschiedlichen Papern verschiedene Keijzer-6 Funktionen beschrieben werden \cite{oliveira_analysing_2018, li_generative_2024, kommenda_local_2018}. 
In dieser Arbeit wurden alle SR Benchmarkprobleme auf das Paper von Cui et al. bezogen \cite{affenzeller_positional_2024}.

\subsection{CGP-Konfigurationen}
\label{subsec:CGPkonfigurationen}

In dieser Arbeit werden unterschiedliche \emph{CGP-Konfigurationen} miteinander verglichen und evaluiert. 
Diese enthalten verschiedene Parametrierungen innerhalb eines CGPs und werden in diesem Abschnitt näher erläutert.\\
Ein Ziel der Arbeit ist es die Effizienz von Rekombination in CGP zu bewerten.
Ebenfalls sollen unterschiedliche Rekombinationsalgorithmen und -konfigurationen miteinander verglichen werden, um eine Aussage über deren Effektivität zu treffen.
Aus diesem Grund müssen für die unterschiedlichen Testszenarien mehrere Rekombinationskonfigurationen getestet werden.
Um eine Vergleichbarkeit der Ergebnisse zu gewährleisten müssen Selektion und Mutation in allen Experimenten gleichen Algorithmen entsprechen.
Diese werden im Folgenden beschrieben.\newline
\textbf{Selektion:} Für die Selektion wird in allen Experimenten das ($\mu$+$\lambda$)-Selektionsverfahren verwendet.
Dabei wurde für die CGP-Konfiguration ohne Rekombinationsschritt nicht $\mu = 1$ festgelegt, obwohl dies den Standard-Einstellungen eines CGP ohne Rekombination entspricht.
Dieser zusätzliche Freiheitsgrad soll einen ausgewogeneren Vergleich zwischen den CGP-Konfigurationen mit und ohne Rekombinationsschritt ermöglichen.
Für die Auswahl der Elitisten wird das neutral search Verfahren herangezogen.\\
\textbf{Mutation:} In allen Experimenten dieser Arbeit wird die Single Active Mutation angewendet.\\

Die nachfolgende Tabelle \ref{table:Rekombinationskonfigurationen} gibt alle Konfigurationen für die \textbf{Rekombination} an, die für jedes Testszenario aus Abschnitt \ref{subsec:testszenarien} getestet werden.

\begin{table}[H]
	\centering
	\begin{tabular}{c | c | c}
		\textbf{Rekombinationsverfahren} & \textbf{Art der Rekombinationsrate} & \textbf{Offset}\\
		\hline
		One-Point Rekombination & konstante Rekombinationsrate  & aktiv \\
		\hline
		Two-Point Rekombination & linear fallende Rekombinationsrate & inaktiv \\
		\hline
		Uniform Rekombination & Rekombinationsrate mit One-Fifth Regel & - \\
		\hline
		keine Rekombination &  - &  - \\
	\end{tabular}
	\caption{Konfigurationen Rekombination}
	\label{table:Rekombinationskonfigurationen}
\end{table}

Zu beachten ist, dass diese einzelnen Einstellungen miteinander kombiniert werden, solange es die Verfahren zulassen.
Falls keine Rekombination ausgeführt wird, wird selbstverständlich auch die Rekombinationsrate nicht angepasst und es kann kein Offset eingeführt werden.
Grundsätzlich werden die Konfigurationskombinationen nach folgendem Muster erstellt:
\begin{itemize}
	\item Auswahl Rekombinationsverfahren
	\item Auswahl Art der Rekombinationsrate
	\item Auswahl Offset aktiv / inaktiv
\end{itemize}

Dementsprechend ergeben sich 19 verschiedene Konfigurationen für den Rekombinationsschritt, die miteinander verglichen werden sollen. 


\subsection{Hyperparameteroptimierung}
\label{subsec:hpo}

Da CGP mehrere Hyperparameter ausweist, die die Effektivität eines CGP-Modells beeinflussen, muss eine \emph{Hyperparameteroptimierung} ausgeführt werden, die einen optimierten Parametersatz ausgibt.
Für jede in Abschnitt \ref{subsec:CGPkonfigurationen} eingeführte CGP-Konfiguration wird eine eigene Hyperparameteroptimierung ausgeführt, da nicht von einem optimierten Datensatz auf den nächsten geschlussfolgert werden kann.
Außerdem müssen die Hyperparameter auf das jeweilige Testszenario angepasst werden.\\
Für die Hyperparameteroptimierungen in dieser Arbeit wird das Julia-Paket HyperOpt.jl verwendet \cite{carlson_baggepinnenhyperoptjl_2025}.
Mit Hilfe des Pakets können die Hyperparameter, sowie deren Wertebereiche angegeben werden, sodass eine automatisierte Optimierung stattfinden kann.
Eben diese werden in folgender Tabelle \ref{table:hyperopt} aufgelistet.

\begin{table}[H]
	\centering
	\begin{tabular}{c | c | c | c}
		\textbf{Parameter} & \textbf{min} & \textbf{max} & \textbf{Schrittweite}\\
		\hline
		Anzahl Rechenknoten & 50 & 2000 & 50 \\
		\hline
		$\mu$ (Anzahl Elitisten) & 2 & 20 & 2\\
		\hline
		$\lambda$ (Anzahl Nachkommen) & 10 & 60 & 2 \\
		\hline
		Offset Rekombination (in Iterationen)& 0 & P:55 / K:300 & P:5 / K:30\\
		\hline
		Konstante Rekombinationsrate & 0,1 & 1,0 & 0,1\\
		\hline
		Fallende Rekombinationsrate (Abzug) & 0,005 & 0,05 & 0,005\\
		\hline
		One-Fifth Regel Rekombinationsrate (Startwert) & 0,3 & 0,05 & 0,75\\
	\end{tabular}
	\caption{Optimierte Hyperparameter und deren Wertebereiche}
	\label{table:hyperopt}
\end{table}

Zu beachten ist, dass $\mu <= \lambda$ gilt und die Hyperparameteranalysen nur für Parity und Keijzer (in Tabelle \ref{table:hyperopt} durch P und K markiert) ausgeführt werden.
Eine ausführliche Begründung liefert Abschnitt \ref{subsec:struktur}.
Außerdem werden die Einträge der Tabelle \ref{table:hyperopt} je nach CGP-Konfiguration verwendet.
Zum Beispiel wird der Wert \glqq Offset Rekombination\grqq\space nur verwendet, wenn der Rekombinationsoffset aktiv ist. 
Dieser Wert wird in Iterationen angegeben, in denen die Rekombination ausgesetzt wird.
Um die obere Grenze des Offsets sinnvoll abzuschätzen wurden zuerst die Hyperparameteranalysen derjeniger CGP-Konfigurationen vorgenommen, die keinen Offset verwenden.
Für jeweils ein Testszenario wurden anschließend die Mittelwerte der benötigten Iterationen berechnet.
Auf Basis dieser Mittelwerte konnten die Offset Wertebereiche sinnvoller gewählt werden, sodass sich der Wert der wahrscheinlich benötigten Iterationen mit der oberen Grenze deckt.
Die drei letzten Zeilen der Tabelle \ref{table:hyperopt} geben die verschiedenen Arten an Rekombinationsraten an, die in dieser Arbeit verglichen werden.
Für jede dieser Ratenarten wird gezielt nur ein Hyperparameter verwendet, um die Rechenzeit der Hyperparameteroptimierung zu reduzieren.
Für die linear fallende Rekombinationsrate gibt dieser Parameter an, mit welcher Schrittweite die Rekombinationsrate pro Iteration sinkt.
In der One-Fifth Regel wird der Startwert der Rekombinationsrate angegeben, also diejenige Rekombinationsrate, mit der das CGP-Modell initialisiert wird.\\

In einer Optimierungsschleife werden pro Parametersatz 10 Testdurchläufe durchgeführt, in denen das CGP trainiert wird.
Für Boolesche Probleme wird die Effizienz die Parametersätze anhand der Iterationen gemessen, die der CGP-Algorithmus braucht, bis er konvergiert.
Bei symbolischer Regression bezieht sich der Vergleich auf die berechnete Fitness.
Es wurde eine Iterationsgrenze eingeführt, ab der der CGP-Algorithmus in der Hyperparameteroptimierung abbricht, um Rechenzeit zu sparen.
Diese Grenze wurde durch vorhergehende Tests so gesetzt, dass nur wenige Ausreißer diese überschreiten.
Trifft dies zu wird bei Booleschen Problemen die Anzahl an benötigten Iterationen verdoppelt, um so das gescheiterte Training härter zu bestrafen.\\
Nach 150 getesteten Parametersätzen bricht die Hyperparameteroptimierung ab und gibt den besten Parametersatz aus.\\

Das verwendete Julia-Paket bietet verschiedene Sampler an.
Der als Standardeinstellung zur Verfügung gestellte Sampler ist ein Random-Sampler.
Da der verwendete BHOB Sampler mit und ohne Hyperband keine Einsparungen in der Rechenzeit ergeben haben, wurde weiterhin der einfach zu konfigurierende Random-Sampler verwendet. 

\subsection{Teststruktur}
\label{subsec:struktur}

Ursprünglich sollte für jedes Testproblem/Testszenario und für jede CGP-Konfiguration eine eigene Hyperparameteroptimierung durchgeführt werden.
Mit den daraus resultierenden Parametersätzen hätten für jede Kombination aus Testszenario und CGP-Konfiguration eine annähernd optimale Lösung gefunden werden können.
Diese hätten anschließend systematisch evaluiert und verglichen werden können.
Angesichts der begrenzten Rechenkapazitäten konnten nur für die beiden leichtesten Testszenarien Parity und Keijzer sinnvolle Hyperparameteranalysen ausgeführt werden.
Für die jeweiligen anderen Szenarien wurde außerdem versucht eine stark reduzierte Hyperparameteranalyse auszuführen, indem alle Parameter, die nichts mit der Rekombination zu tun haben aus den Ergebnissen von Cui et al. herangezogen werden \cite{cui_results}.
So sollten nur die für die Rekombination relevanten Parameter optimiert werden, also die Rekombinationsrate und gegebenenfalls der Offset.
Bei den Versuchen dieses Testverfahren für die umfangreicheren Testszenarien auszuführen, wurde ebenfalls festgestellt, dass die verfügbare Rechenkapazitäten nicht ausreichen.
Diese Beobachtung wurde auch gemacht als der Offset-Parameter bei der Optimierung vollständig herausgenommen wurde.\\
Aus diesen Gründen wurde eine neue Methodik entwickelt, die in diesem Abschnitt näher erläutert werden soll.
Die Teststruktur wird in zwei voneinander unabhängige Testblöcke geteilt.

\subsubsection{1. Testblock: einfache Testszenarien}
\label{subsub:ersterTestblock}

Für die einfachen Testszenarien Parity und Keijzer kann eine Hyperparameteranalyse trotz eingeschränkter Rechenzeit ausgeführt werden, indem die Iterationenzahl bis zum Abbruch des CGP-Algorithmus heruntergesetzt werden.
Dieser wird schrittweise reduziert, bis die Hyperparameteranalyse ausgeführt werden kann.\\
Um zu Überprüfen, ob die angepassten Iterationsgrenzen für Parity sinnvoll sind, werden die Ergebnisse von Cui et al. herangezogen. 
Dabei wurden nur die Ergebnisse mit ($\mu + \lambda$)-Selektion verwendet, die mit den CGP-Konfigurationen dieser Arbeit entsprechen \cite{cui_results}.
Es ergibt sich ein HPDI-Maximalwert von ca. 495 Iterationen. 
Mit einer Iterationsgrenze von 500 ist es wahrscheinlich, dass vor allem schlechte Parametersätze zu einer Überschreitung dieses Werts führen.
Durch die erhöhte Bestrafung dieser Überschreitung, wird sichergestellt, dass die sichere Konvergenz des CGP-Algorithmus bis zur Iterationsgrenze priorisiert wird.\\
Da für Keijzer die Hyperparameteranalyse auf Basis der Fitness ausgewertet wird, können Güte-Aussagen ebenfalls getroffen werden, auch wenn der CGP-Algorithmus nicht vollständig konvergiert ist, da bereits vor Erreichen des Stopp-Kriteriums eine Aussage über das Konvergenzverhalten getroffen werden kann.
Demnach wird für Keijzer die unter den Rechenzeit-Umständen höchste Iterationsgrenze von 500 Iterationen als genügend für die Hyperparameteroptimierung angesehen.\\

Mit Hilfe der optimierten Parametersätze können anschließend jeweils 50 CGP-Modelle pro Testszenario und CGP-Konfiguration ausgeführt werden.
Die Ergebnisse dieser Modelle können verwendet werden, um die Güte der CGP-Konfigurationen auf einfache Testszenarien zu evaluieren.
Das Evaluierungsverfahren wird in Abschnitt \ref{sec:Evaluation} näher erläutert.

\subsubsection{2. Testblock: komplexe Testszenarien}
\label{subsub:zweiterTestblock}

Da durch die erhöhte Rechenzeit der komplexeren Testszenarien keine sinnvolle Hyperparameteroptimierung ausführen lässt, wird für diese Fälle eine andere Teststrategie entwickelt.\\
Diejenigen Hyperparameter eines CGP-Modells, die nicht mit Rekombination in Verbindung stehen, werden aus den Ergebnissen von Cui et al. herangezogen \cite{cui_results}.
Die Rekombinationsrate wird variiert und mit diesen Parametern in CGP-Modelle eingepflegt.
Für jede CGP-Konfiguration werden 50 Testdurchläufe ausgeführt, um eine statistische Auswertung ausführen zu können.
Dabei werden die CGP-Modellen gegebenenfalls nicht bis zur vollständigen Konvergenz trainiert, um die Rechenzeit zu reduzieren. 
Für Boolesche Probleme werden den CGP-Modelle dabei weniger Iterationen Trainingszeit zur Verfügung gestellt als für SR Probleme, da diese in der Hyperparameteranalyse von Cui et al. mehr Rechenknoten brauchen und somit für jeweils eine Iteration mehr Rechenzeit benötigen als es bei SR der Fall ist. \cite{cui_results}\\
Da sich die Wirkung von Rekombinationsrate und Offset gegenseitig beeinflussen kann, ist es sinnvoller die Bewertung der beiden Parameter einzeln zu betrachten.
Aufgrund der hohen Anzahl der zu bewertenden Testergebnisse, die sich bereits für einen variierenden Parameter ergeben, soll nur einer dieser Parameter in dieser Arbeit näher betrachtet werden.
Dieser Parameter ist wie bereits beschrieben die Rekombinationsrate.
Dies ergibt sich daraus, dass die Ergebnisse der Hyperparameteranalyse der einfachen Tests bereits vermuten lassen, dass der Offset keinen deutlichen Mehrwert für das CGP-Training mit sich bringt.
Details zu den jeweiligen Ergebnissen können in den Abschnitten \ref{parity:analyseRohdaten} und \ref{keijzer:analyseRohdaten} nachgelesen werden.
Außerdem können mit Hilfe der Rekombinationsrate nähere Erkenntnisse zu den unterschiedlichen Rekombinationsarten gewonnen werden, die in dieser Arbeit verglichen werden.\\
Für die Evaluation stehen nach dem Testdurchlauf die Ergebnisse mehrerer CGP-Kon\-fi\-gu\-ra\-tio\-nen zur Verfügung, die allerdings nicht unbedingt die Ergebnisse der CGPs mit den jeweils besten Parametersätzen darstellen, da keine Hyperparameteroptimierung ausgeführt wurde.
Trotzdem können die Ergebnisse verwendet werden, um einen näheren Einblick zum Verhalten des CGP-Modells zu erhalten, wenn die Rekombinationsrate variiert wird.\\
Nähere Informationen zur Evaluierung werden in Abschnitt \ref{sec:Evaluation} gegeben.


\section{Evaluation}
\label{sec:Evaluation}

Für die Auswertung der Ergebnisse werden für jedes CGP-Training verschiedene Metriken aufgezeichnet, die einen Einblick in die Effizienz der Modelle geben sollen.
Diese werden für jede Trainingsiteration gespeichert, um den Verlauf beobachten und bewerten zu können.
Die folgende Liste gibt die Metriken an, die in dieser Arbeit näher betrachtet werden:
\begin{itemize}
	\item Fitness nach Rekombination
	\item Fitness nach Mutation
	\item Anzahl aktiver Knoten
	\item Anteil aktiver Knoten
\end{itemize}

Die Evaluation umfasst unterschiedliche Techniken zur Bewertung der ausgezeichneten Daten.
Diese werden im Folgenden eingeführt und erläutert.\\

\textbf{Analyse der Rohdaten:} Der erste Evaluationsschritt umfasst eine händische Analyse der Rohdaten.
Dabei werden die Ergebnisse der Hyperparameteranalyse näher betrachtet und bewertet.
Es werden erste Erkenntnisse über die Effizienz der verschiedenen Rekombinationstypen gesammelt, indem beispielsweise die Anzahl der Rechenknoten verglichen wird.
Außerdem wird beobachtet wie die unterschiedlichen Rekombinationsparameter gesetzt werden.\\
Des weiteren werden die Ergebnisse des CGP-Trainings näher analysiert.
Der Trainingserfolg zwischen Rekombination und Mutation können anhand der jeweiligen Fitness-Werte miteinander verglichen werden.\\

\textbf{Bayes'sche Analyse:} Die Bayes'sche Analyse wird einerseits für die Sortierung der Effizienz der CGP-Konfigurationen verwendet. 
Dafür wird wie in Abschnitt \ref{sec:bayesian} beschrieben das Plackett-Luce-Modell verwendet.
Für die einfacheren Testszenarien Parity und Keijzer können so die Ergebnisse, der aus der Hyperparameteranalyse erhaltenen besten CGP-Konfigurationen miteinander verglichen werden.\\
Für weitere Bewertungen wird das Gammaverteilung-basierte genutzt.
Durch die Berechnung des Mittelwerts und HPDI der Iterationen für jede CPG-Konfiguration können sowohl die einfacheren als auch die komplexeren Testszenarien ausgewertet werden.
Für Parity und Keijzer kann so eingeschätzt werden, welche CGP-Konfiguration die Ausgangsprobleme schneller lösen kann als andere.
Außerdem kann bewertet werden wie hoch die Streuung dieser Ergebnisse ist.
Für die komplexeren Ausgangsprobleme kann beobachtet werden, welche Auswirkungen die Änderung der Rekombinationsparameter auf die Effizienz der CGP-Modelle hat.\\
Die \emph{Prior-Sensitivitätsanalyse}, die Cui et al. in ihrem Paper untersuchen, wird aus Gründen des Umfangs in dieser Arbeit nicht näher betrachtet \cite{cui_equidistant_2023}.\\

\textbf{Graphische Evaluation:} Für alle Testszenarien kann neben der bayes'schen Analyse eine graphische Evaluation ausgeführt werden.
Dafür werden nicht die Endergebnisse des CGP-Trainings betrachtet, sondern deren Verlauf.
Es werden die Fitnesswerte und Anteile der aktiven Knoten über die Iterationen hinweg geplottet.
Dabei werden die Mittelwerte und Standardabweichungen der Metriken verwendet.
Im Anschluss können die Plots visuell bewertet werden.\\

