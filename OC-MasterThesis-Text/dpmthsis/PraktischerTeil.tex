\chapter{Praktischer Teil}
\label{praktischer Teil}

\section{Aufbau der Experimente}
\label{sec:aufbauExperimente}

Für die Beantwortung der Forschungsfragen werden unterschiedliche Experimente ausgeführt, deren Ergebnisse in dieser Arbeit ausgewertet und interpretiert werden sollen.
Der Programmcode für die Experimente wurde in der Sprache Julia verfasst.
Dabei fand eine Orientierung an folgendem Code von Henning Cui statt: \cite{cuihen_cuihencgp_with_crossover_strategies_2024}\\
Um Ergebnisse von Ausgangsproblemen aus unterschiedlichen Domänen für eine umfangreichere Bewertung zur Verfügung zu stellen, werden mehrere Benchmark-Testszenarien überprüft.
Diese werden in den folgenden Abschnitten näher betrachtet.

\subsection{Testszenarien}
\label{subsec:testszenarien}

\subsubsection{Boolean Problems}
\label{subsubsec:booleanProblems}

Nach der Aussage von Kalkreuth et al. spielen Boolean Problems eine wichtige Rolle in der Forschung zu GP.
Grundsätzlich ist bei Boolean Problems das Ziel einen sinnvollen Zusammenhang zwischen Ein- und Ausgaben zu generieren.
Dieser wird von Boolean Funktionen bestimmt, welche wiederum durch Boolean-Ausdrücke mathematisch beschrieben werden können.
Die verschiedenen Boolean Funktionen können durch Wahrheitstabellen dargestellt werden, in denen die jeweiligen Ein- und Ausgaben miteinander verknüpft werden. \cite{kalkreuth_towards_2023}
Das Ziel von CGP-Algorithmen ist es aus Eingängen die richtigen Ausgänge zu generieren, welche dem Mapping der Boolean Funktionen entsprechen.\\

Insgesamt werden in dieser Arbeit vier Boolean Benchmark Problems für die Evaluation der CGP Algorithmen betrachtet.
Die Auswahl dieser beruht auf der Argumentationskette von Cui et al., die für sinnvoll befunden wird.

TODO: hier die Argumente für die Auswahl dieser vier BBP treffen -> für Argumentationskette Henning zitieren und deren Quellen mit angeben\\
\cite{cui_equidistant_2023}\\


TODO: Die vier Probleme näher beschreiben: Inputs, Outputs und Berechnung

\subsubsection{Symbolische Regression}
\label{subsubsec:symbolicRegression}

\section{Ergebnisse}
\label{Ergebnisse}

\begin{itemize}
    \item Versuchsaufbau und Durchführung
    \begin{itemize}
        \item an Hennings Code orientiert
        \item Testszenarien -> welche Testdaten und Berechnung fitness
        \begin{itemize}
            \item boolean Problems
            \item symbolic regression
            \item ggf. Ameisenoptimierungsproblem
        \end{itemize}
        \item weitere Einstellungen (Welche Selektionsverfahren, Mutationsverfahren, Rekomb...)
        \item Hyperparameteroptimierung
        \begin{itemize}
        	\item HPO wird in Grundlagen nicht erklärt also hier kurz erwähnen, dass die besten Parameter gesucht werden also eine HPO ausgeführt wird
            \item Welche Bib benutzt
            \item Welche Parameter optimiert; mit welchen Ranges
            \item 10 Ausführungen pro Optimierungsschritt
            \item Probleme Rechenzeit HPO
            \item verschiedene Sampler keinen Mehrwert
        \end{itemize}
        \item Ausführen mehrerer Durchläufe, um statistische Auswertung vorzunehmen
    \end{itemize}
    \item Ergebnisse und Evaluation
    \begin{itemize}
        \item Metriken zur Auswertung
        \item händische Auswertung des zeitlichen Verlaufs der Metriken (Mittelwert und Standardabweichung)
        \item bayesian Auswertung der Endergebnisse -> wie viele Iterationen (erklären wieso Bayes verwendet wird: Henning sagt in Paper, dass andere Verteilungen das Modell nicht gut beschreiben; siehe negative Werte für Iterationen)
        \item Plankett-Luce-Modell gibt Wahrscheinlichkeit bestes Ergebnis zu sein -> wie in Hennings Paper
        \item cmpbayes verwendet Markov Chain Monte-Carlo Sampling -> also auch verwenden
        \item HPDI für Bewertung der Endergebnisse (Iterationen bis konvergent)
        \item prior sensitivity analysis nicht machen (to ensure robustness of all models)
        \item ggf Bewertung der statistischen Aussagekraft mit ANOVA
    \end{itemize}
\end{itemize}

